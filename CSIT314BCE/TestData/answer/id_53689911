<p>The assumption by other answers that one needs to sort the data is not correct.</p>

<p>The following code does not sort the entire array, but only 200-element segments of it, and thereby runs the fastest.</p>

<p>Sorting only k-element sections completes the pre-processing in linear time, <code>O(n)</code>, rather than the <code>O(n.log(n))</code> time needed to sort the entire array.</p>

<pre><code>#include &lt;algorithm&gt;
#include &lt;ctime&gt;
#include &lt;iostream&gt;

int main() {
    int data[32768]; const int l = sizeof data / sizeof data[0];

    for (unsigned c = 0; c &lt; l; ++c)
        data[c] = std::rand() % 256;

    // sort 200-element segments, not the whole array
    for (unsigned c = 0; c + 200 &lt;= l; c += 200)
        std::sort(&amp;data[c], &amp;data[c + 200]);

    clock_t start = clock();
    long long sum = 0;

    for (unsigned i = 0; i &lt; 100000; ++i) {
        for (unsigned c = 0; c &lt; sizeof data / sizeof(int); ++c) {
            if (data[c] &gt;= 128)
                sum += data[c];
        }
    }

    std::cout &lt;&lt; static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC &lt;&lt; std::endl;
    std::cout &lt;&lt; "sum = " &lt;&lt; sum &lt;&lt; std::endl;
}
</code></pre>

<p>This also "proves" that it has nothing to do with any algorithmic issue such as sort order, and it is indeed branch prediction.</p>

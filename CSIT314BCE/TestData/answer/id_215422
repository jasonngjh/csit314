<p>
Just for the sake of completeness, here's a brain dump of related information...</p>

<p>As others have noted, <code>string</code> is an alias for <code>System.String</code>. They compile to the same code, so at execution time there is no difference whatsoever. This is just one of the aliases in C#. The complete list is:</p>

<pre class="lang-c# prettyprint-override"><code>object:  System.Object
string:  System.String
bool:    System.Boolean
byte:    System.Byte
sbyte:   System.SByte
short:   System.Int16
ushort:  System.UInt16
int:     System.Int32
uint:    System.UInt32
long:    System.Int64
ulong:   System.UInt64
float:   System.Single
double:  System.Double
decimal: System.Decimal
char:    System.Char
</code></pre>

<p>Apart from <code>string</code> and <code>object</code>, the aliases are all to value types. <code>decimal</code> is a value type, but not a primitive type in the CLR. The only primitive type which doesn't have an alias is <code>System.IntPtr</code>.</p>

<p>In the spec, the value type aliases are known as "simple types". Literals can be used for constant values of every simple type; no other value types have literal forms available. (Compare this with VB, which allows <code>DateTime</code> literals, and has an alias for it too.)</p>

<p>There is one circumstance in which you <em>have</em> to use the aliases: when explicitly specifying an enum's underlying type. For instance:</p>

<pre class="lang-c# prettyprint-override"><code>public enum Foo : UInt32 {} // Invalid
public enum Bar : uint   {} // Valid
</code></pre>

<p>That's just a matter of the way the spec defines enum declarations - the part after the colon has to be the <em>integral-type</em> production, which is one token of <code>sbyte</code>, <code>byte</code>, <code>short</code>, <code>ushort</code>, <code>int</code>, <code>uint</code>, <code>long</code>, <code>ulong</code>, <code>char</code>... as opposed to a <em>type</em> production as used by variable declarations for example. It doesn't indicate any other difference.</p>

<p>Finally, when it comes to which to use: personally I use the aliases everywhere for the implementation, but the CLR type for any APIs. It really doesn't matter too much which you use in terms of implementation - consistency among your team is nice, but no-one else is going to care. On the other hand, it's genuinely important that if you refer to a type in an API, you do so in a language-neutral way. A method called <code>ReadInt32</code> is unambiguous, whereas a method called <code>ReadInt</code> requires interpretation. The caller could be using a language that defines an <code>int</code> alias for <code>Int16</code>, for example. The .NET framework designers have followed this pattern, good examples being in the <code>BitConverter</code>, <code>BinaryReader</code> and <code>Convert</code> classes.</p>
